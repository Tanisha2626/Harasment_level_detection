{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanisha2626/Harasment_level_detection/blob/main/Harasment_level_Detection_Hindi_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZBrSpdk4S5w"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install /content/transformers/\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmMKCJ-dG2ge"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import transformers\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBSxMIY36Gdp"
      },
      "source": [
        "### TPU set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk2rAvu3y5Vk"
      },
      "source": [
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFCqNsgb6ARO"
      },
      "source": [
        "### Downloading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apm76bwvBo7d"
      },
      "source": [
        "!git clone https://github.com/Tanisha2626/Harasment_level_detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKKJ-JmZG2g3"
      },
      "source": [
        "raw_train_df =  pd.read_csv(\"Harasment_level_detection/trac2_hin_train.csv\")\n",
        "raw_train_df['split'] = 'train'\n",
        "print(raw_train_df.columns)\n",
        "print(raw_train_df['Sub-task A'].value_counts())\n",
        "print(raw_train_df['Sub-task B'].value_counts())\n",
        "print(f\"Size of 'train' split: {len(raw_train_df)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSM9RGfRG2g8"
      },
      "source": [
        "raw_dev_df =  pd.read_csv(\"Harasment_level_detection/trac2_hin_dev.csv\")\n",
        "raw_dev_df['split'] = 'dev'\n",
        "print(raw_dev_df.columns)\n",
        "print(raw_dev_df['Sub-task A'].value_counts())\n",
        "print(raw_dev_df['Sub-task B'].value_counts())\n",
        "print(f\"Size of 'dev' split: {len(raw_dev_df)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2TUSO4ZJNvM"
      },
      "source": [
        "test_df =  pd.read_csv(\"Harasment_level_detection/trac2_hin_test.csv\")\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W99Hc1Y-G2hA"
      },
      "source": [
        "# Concatinate both train and dev dfs together\n",
        "data_df = pd.concat([raw_dev_df, raw_train_df], ignore_index= True)\n",
        "data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z1dLUbuG2hD"
      },
      "source": [
        "### Samples given per label size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad1zsEMPG2hE"
      },
      "source": [
        "print(f'Total dev + train size = {len(data_df)}\\n')\n",
        "print(data_df['Sub-task A'].value_counts(),'\\n')\n",
        "print(data_df['Sub-task B'].value_counts(),'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hY0WnQuG2hH"
      },
      "source": [
        "### Label emcoder for Sub-task A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdJz_1d_bhV1"
      },
      "source": [
        "task_a_label_dict = {'NAG':0, 'OAG':1, 'CAG':2}\n",
        "print(task_a_label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhws_lcgbYwy"
      },
      "source": [
        "data_df_task_a = data_df[['ID','Text','Sub-task A','split']].copy()\n",
        "data_df_task_a.columns.values[1] = 'text'\n",
        "data_df_task_a.columns.values[2] = 'label'\n",
        "data_df_task_a.loc[:,'label'] = data_df_task_a.loc[:,'label'].map(task_a_label_dict)\n",
        "data_df_task_a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPAImYUnb21p"
      },
      "source": [
        "print(\"Num samples per class\")\n",
        "print(data_df_task_a.label.value_counts())\n",
        "\n",
        "print(\"\\nNum samples per split\")\n",
        "print(data_df_task_a.split.value_counts())\n",
        "\n",
        "print(\"\\nLabel counts in dev split\")\n",
        "print(data_df_task_a[data_df_task_a.split=='dev'].label.value_counts())\n",
        "\n",
        "print(\"\\nLabel counts in train split\")\n",
        "print(data_df_task_a[data_df_task_a.split=='train'].label.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O7vBHfC5iJd"
      },
      "source": [
        "### Label encoder for Sub-task B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqQas0q9G2hI",
        "scrolled": true
      },
      "source": [
        "task_b_label_dict = {'NGEN':0, 'GEN':1}\n",
        "print(task_b_label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nzmWDI7G2hN"
      },
      "source": [
        "\n",
        "data_df_task_b = data_df[['ID','Text','Sub-task B','split']].copy()\n",
        "data_df_task_b.columns.values[1] = 'text'\n",
        "data_df_task_b.columns.values[2] = 'label'\n",
        "data_df_task_b.loc[:,'label'] = data_df_task_b.loc[:,'label'].map(task_b_label_dict)\n",
        "data_df_task_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQxb1PR7G2hR"
      },
      "source": [
        "print(\"Num samples per class\")\n",
        "print(data_df_task_b.label.value_counts())\n",
        "\n",
        "print(\"\\nNum samples per split\")\n",
        "print(data_df_task_b.split.value_counts())\n",
        "\n",
        "print(\"\\nLabel counts in dev split\")\n",
        "print(data_df_task_b[data_df_task_b.split=='dev'].label.value_counts())\n",
        "\n",
        "print(\"\\nLabel counts in train split\")\n",
        "print(data_df_task_b[data_df_task_b.split=='train'].label.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri9x5Ksi5RL0"
      },
      "source": [
        "# Sub-task B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmc7uQXkDP2l"
      },
      "source": [
        "gb = data_df_task_b.groupby('split')\n",
        "grps = [gb.get_group(x) for x in gb.groups]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NL4pCY1uDp4I",
        "outputId": "ecaa7268-0c39-4257-adae-d3f2b9bee3f6"
      },
      "source": [
        "grps[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>C4.131</td>\n",
              "      <td>Bollywood film dekhne ke samay logic ghar mein...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>C4.638</td>\n",
              "      <td>Chutiya movie...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>C38.598</td>\n",
              "      <td>Us jaat bnde ka khene ka matlab tha mar daluga...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>C4.2101.1</td>\n",
              "      <td>@Feminism Is CANCER *un feminist yeh sahi hai ...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>C29.14.2</td>\n",
              "      <td>Amrit Anand अब तो जुड़े ही है उनको बोलो जुड़ने</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4976</th>\n",
              "      <td>C38.455</td>\n",
              "      <td>Asexual h.. bisexual... homosexual... bhai ase...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4977</th>\n",
              "      <td>C4.203</td>\n",
              "      <td>Video pura dekne ke pahile hi mai bhai ke vide...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4978</th>\n",
              "      <td>C45.709</td>\n",
              "      <td>konsa place hai bhai ...nam bolo</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4979</th>\n",
              "      <td>C4.420.1</td>\n",
              "      <td>Kuch zada hi likh diya 🙄</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4980</th>\n",
              "      <td>C7.1913.5</td>\n",
              "      <td>scary tube par kya woh karna sahi tha? Pucha k...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3984 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  ...  split\n",
              "997      C4.131  ...  train\n",
              "998      C4.638  ...  train\n",
              "999     C38.598  ...  train\n",
              "1000  C4.2101.1  ...  train\n",
              "1001   C29.14.2  ...  train\n",
              "...         ...  ...    ...\n",
              "4976    C38.455  ...  train\n",
              "4977     C4.203  ...  train\n",
              "4978    C45.709  ...  train\n",
              "4979   C4.420.1  ...  train\n",
              "4980  C7.1913.5  ...  train\n",
              "\n",
              "[3984 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kac2u9G3Yqer"
      },
      "source": [
        "### Solving class balance problem in Gender target classification dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl0k4Zk5E0I-"
      },
      "source": [
        "train_data = grps[1]\n",
        "gb = train_data.groupby('label')\n",
        "train_grps = [gb.get_group(x) for x in gb.groups]\n",
        "\n",
        "class_0_sample = grps[0].sample(n=600)\n",
        "\n",
        "frames = train_grps[1:2]+[class_0_sample]\n",
        "result=pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9HAqRUc-Fg5j",
        "outputId": "9926a00e-bed6-4f3b-a8cc-c1a0413fe99d"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>C4.974</td>\n",
              "      <td>Lit sir🔥bhenco desh bhakti mai bhi item song p...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>C36.1070</td>\n",
              "      <td>आर्मी में हमे मर्द चाहिए,हिजड़े नही ।</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>C33.485</td>\n",
              "      <td>Ye chutiya ladki kon h be ... ... kuch v baak ...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>C4.694.1</td>\n",
              "      <td>@KHAN SHAHAB abey jhaatu overseas ki baat mat ...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1041</th>\n",
              "      <td>C7.1756</td>\n",
              "      <td>Abe bc ye kis angle se movie review that Bhai ...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>C4.175</td>\n",
              "      <td>Gyaan mt chod chl</td>\n",
              "      <td>1</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>C4.1663</td>\n",
              "      <td>Kabir Singh se sirf or sirf 1 seekh milti h  \\...</td>\n",
              "      <td>0</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>C4.1996.2</td>\n",
              "      <td>@Fact Park bhai 50 minutes se jyada tak kuch n...</td>\n",
              "      <td>0</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>C19.169.2</td>\n",
              "      <td>Review ke liye sirf Mubarak</td>\n",
              "      <td>0</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>C59.2210</td>\n",
              "      <td>Very nice my friend my name Sahil bhai Bollywo...</td>\n",
              "      <td>0</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1261 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  ...  split\n",
              "1005     C4.974  ...  train\n",
              "1006   C36.1070  ...  train\n",
              "1024    C33.485  ...  train\n",
              "1036   C4.694.1  ...  train\n",
              "1041    C7.1756  ...  train\n",
              "...         ...  ...    ...\n",
              "780      C4.175  ...    dev\n",
              "167     C4.1663  ...    dev\n",
              "112   C4.1996.2  ...    dev\n",
              "877   C19.169.2  ...    dev\n",
              "175    C59.2210  ...    dev\n",
              "\n",
              "[1261 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV0mKnVk6Or6"
      },
      "source": [
        "### Model for sub-task b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuW0k9DRQyhb"
      },
      "source": [
        "def build_model_task_b(transformer, num_classes, max_len=512):\n",
        "\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    out = Dense(num_classes, activation='softmax')(cls_token)\n",
        "    # X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.1))(sequence_output)\n",
        "    # X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "    # X = tf.keras.layers.Dense(50, activation='relu')(X)\n",
        "    # X = tf.keras.layers.Dropout(0.2)(X)\n",
        "    # out = tf.keras.layers.Dense(num_classes, activation='softmax')(X)\n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    #model.layers[1].trainable = False\n",
        "    model.compile(Adam(lr=1e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAq_gLJ_6j2s"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CtVao6pQ12w"
      },
      "source": [
        "EPOCHS = 2\n",
        "BATCH_SIZE = 16 #* strategy.num_replicas_in_sync\n",
        "MAX_LEN = 128\n",
        "MODEL = 'jplu/tf-xlm-roberta-base'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APXmQP8s6op1"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV_zsFzJRbsY"
      },
      "source": [
        "from transformers import XLMRobertaTokenizer\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True, add_special_tokens=True,max_length=512, pad_to_max_length=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_lcemyWmFjR"
      },
      "source": [
        "x_train = np.asarray(tokenizer.batch_encode_plus(result['text'],pad_to_max_length=True, max_length=128, return_attention_mask=False)['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ91yI_Imoi3"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zicspfp9qDv1"
      },
      "source": [
        "y_train = result.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmNdbJT0fVSR"
      },
      "source": [
        "y_train = np.asarray(y_train, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaDw4_-MD95p"
      },
      "source": [
        "x_val = np.asarray(tokenizer.batch_encode_plus(grps[0]['text'],pad_to_max_length=True, max_length=128, return_attention_mask=False)['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F01gejQIEEis",
        "outputId": "c0bb3ad3-42d4-4f8a-fbda-0107f62182db"
      },
      "source": [
        "x_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(997, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o17I-VgnEJnC"
      },
      "source": [
        "y_val = grps[0].label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCMYfuNdEOcV"
      },
      "source": [
        "y_val = np.asarray(y_val, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fy3nywDKvO_"
      },
      "source": [
        "x_test = np.asarray(tokenizer.batch_encode_plus(test_df['Text'],pad_to_max_length=True, max_length=128, return_attention_mask=False)['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-ALznf1X1pu"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bflCMarEaMtz"
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_train, y_train))\n",
        "    .repeat()\n",
        "    .shuffle(2048)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "val_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_val, y_val))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_QPbHxT6837"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K64jMyljd3Ju"
      },
      "source": [
        "# Train on CPU/GPU\n",
        "\n",
        "transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
        "model_task_b = build_model_task_b(transformer_layer,num_classes=2, max_len=MAX_LEN)\n",
        "model.summary()\n",
        "\n",
        "n_steps = x_train.shape[0] // BATCH_SIZE\n",
        "train_history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=n_steps,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLFpHHhRi57q"
      },
      "source": [
        "# Train on TPU\n",
        "\n",
        "with strategy.scope():\n",
        "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
        "    model_task_b = build_model_task_b(transformer_layer,num_classes=2, max_len=MAX_LEN)\n",
        "model_task_b.summary()\n",
        "\n",
        "n_steps = x_train.shape[0] // BATCH_SIZE\n",
        "train_history = model_task_b.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=n_steps,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=100\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgie--igHCvp"
      },
      "source": [
        "y_pred = np.argmax(model_task_b.predict(x_val),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WShqZaiLPUWP"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "print(\"Accuracy score =\",accuracy_score(y_pred,y_val))\n",
        "print(\"Precision score =\",precision_score(y_pred,y_val))\n",
        "print(\"Recall score =\",recall_score(y_pred,y_val))\n",
        "print(\"F1 score =\",f1_score(y_pred,y_val))\n",
        "print(confusion_matrix(y_pred,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKnXRfQB7AbT"
      },
      "source": [
        "## Testing function for sub-task b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRF2yay5cf2P"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "def gender_bias(sentence):\n",
        "  text = [sentence]\n",
        "  df_input = pd.DataFrame(text)\n",
        "  x_input = np.asarray(tokenizer.batch_encode_plus(df_input[0],pad_to_max_length=True, max_length=128, return_attention_mask=False)['input_ids'])\n",
        "  class_probs = model_task_b.predict(x_input)\n",
        "  pred_class = np.argmax(class_probs,axis=1)[0]\n",
        "  gender = list(task_b_label_dict.keys())[pred_class]\n",
        "  return gender, class_probs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Ol2kjM7FAb"
      },
      "source": [
        "## GUI input for sub-task b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ZUZYLX09dCo5"
      },
      "source": [
        "#@title Is this comment gender targeted?\n",
        "sentence = \"Woh bohot bada gadha hai\" #@param {type:\"string\"}\n",
        "gender, class_probs = gender_bias(sentence)\n",
        "print(\"Is it Gender Targeted ? = \",gender)\n",
        "print(\"Not Gender Targeted probability =\",class_probs[0])\n",
        "print(\"Gender Targeted probability =\",class_probs[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04TIXlGxsIwd"
      },
      "source": [
        "# Sub-Task-A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlpfTszCh6JH"
      },
      "source": [
        "gb = data_df_task_a.groupby('split')\n",
        "grps = [gb.get_group(x) for x in gb.groups]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIr7Lyvqh6JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6f79b8-7aff-48c5-9277-30cdb7308300"
      },
      "source": [
        "x_train = np.asarray(tokenizer.batch_encode_plus(grps[1]['text'],pad_to_max_length=True, max_length=128, return_attention_mask=False)['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_0VeOfXh6JJ"
      },
      "source": [
        "y_train = grps[1].label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uibp6U2Kh6JM"
      },
      "source": [
        "y_train = np.asarray(y_train, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wtBUcOWh6JM"
      },
      "source": [
        "x_val = np.asarray(tokenizer.batch_encode_plus(grps[0]['text'],pad_to_max_length=True, max_length=128, return_attention_mask=False)['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysHYMd4Jh6JM"
      },
      "source": [
        "y_val = grps[0].label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_46kDJ3dh6JM"
      },
      "source": [
        "y_val = np.asarray(y_val, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKMYPfwah6JO"
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_train, y_train))\n",
        "    .repeat()\n",
        "    .shuffle(2048)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "val_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_val, y_val))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jh1ZiD27J9c"
      },
      "source": [
        "## Model for sub-task A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnSqJuDYr2_D"
      },
      "source": [
        "def build_model_task_a(transformer, num_classes, max_len=512):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    #cls_token = sequence_output[:, 0, :]\n",
        "    #out = Dense(num_classes, activation='softmax')(cls_token)\n",
        "    X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.1))(sequence_output)\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "    X = tf.keras.layers.Dense(50, activation='relu')(X)\n",
        "    X = tf.keras.layers.Dropout(0.2)(X)\n",
        "    out = tf.keras.layers.Dense(num_classes, activation='softmax')(X)\n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    #model.layers[1].trainable = False\n",
        "    model.compile(Adam(lr=1e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOVqcSWZ7QH_"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCbP-ol8xdvb"
      },
      "source": [
        "# Train on CPU/GPU\n",
        "\n",
        "transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
        "model_task_a = build_model_task_a(transformer_layer,num_classes=3, max_len=MAX_LEN)\n",
        "model_task_a.summary()\n",
        "\n",
        "n_steps = x_train.shape[0] // BATCH_SIZE\n",
        "train_history = model_task_a.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=n_steps,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=20\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6bwfYJ-h6JO"
      },
      "source": [
        "# Train on TPU\n",
        "\n",
        "with strategy.scope():\n",
        "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
        "    model_task_a = build_model_task_a(transformer_layer, num_classes=3, max_len=MAX_LEN)\n",
        "model_task_a.summary()\n",
        "\n",
        "n_steps = x_train.shape[0] // BATCH_SIZE\n",
        "train_history = model_task_a.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=n_steps,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md7NI66FXDHt"
      },
      "source": [
        "y_pred = np.argmax(model_task_a.predict(x_val),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUU0QHSKXDHv"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "print(\"Accuracy score =\",accuracy_score(y_pred,y_val))\n",
        "print(\"Precision score =\",precision_score(y_pred,y_val,average='macro'))\n",
        "print(\"Recall score =\",recall_score(y_pred,y_val,average='macro'))\n",
        "print(\"F1 score =\",f1_score(y_pred,y_val,average='macro'))\n",
        "print(confusion_matrix(y_pred,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHld0sQh7TNp"
      },
      "source": [
        "## Testing function for sub-task A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZo3QFpeiKSE"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "def agression(sentence):\n",
        "  text = [sentence]\n",
        "  df_input = pd.DataFrame(text)\n",
        "  x_input = np.asarray(tokenizer.batch_encode_plus(df_input[0],pad_to_max_length=True, max_length=128, return_attention_mask=False)['input_ids'])\n",
        "  class_probs = model_task_a.predict(x_input)\n",
        "  pred_class = np.argmax(class_probs,axis=1)[0]\n",
        "  agression = list(task_a_label_dict.keys())[pred_class]\n",
        "  return agression, class_probs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGv2GX5O7XYi"
      },
      "source": [
        "## GUI input for sub-task A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebHVtAg24EHF",
        "outputId": "46a50eda-d607-43c7-c3c6-f35835b342d6"
      },
      "source": [
        "#@title Agression Level\n",
        "sentence = \"Yaha aaoge to sar yehi rakh ke jaana padega\" #@param {type:\"string\"}\n",
        "agr, class_probs = agression(sentence)\n",
        "print(\"Agression level = \",agr)\n",
        "print(\"NAG probability =\",class_probs[0])\n",
        "print(\"OAG probability =\",class_probs[1])\n",
        "print(\"CAG probability =\",class_probs[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agression level =  OAG\n",
            "NAG probability = 0.30922744\n",
            "OAG probability = 0.35746512\n",
            "CAG probability = 0.33330742\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}